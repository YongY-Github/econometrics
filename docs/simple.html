<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Applied Econometrics Notes - 1&nbsp; Simple Regression Model: Basics of OLS</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./assumptions.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./simple.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple Regression Model: Basics of OLS</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Applied Econometrics Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./simple.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple Regression Model: Basics of OLS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assumptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Classical Linear Model (Gauss-Markov) Assumptions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multiple.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Multiple Regression Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1.1</span> Introduction</a></li>
  <li><a href="#types-of-data" id="toc-types-of-data" class="nav-link" data-scroll-target="#types-of-data"><span class="header-section-number">1.2</span> Types of Data</a></li>
  <li><a href="#the-simple-regression-model" id="toc-the-simple-regression-model" class="nav-link" data-scroll-target="#the-simple-regression-model"><span class="header-section-number">1.3</span> The Simple Regression Model</a>
  <ul class="collapse">
  <li><a href="#the-population-regression-function-prf" id="toc-the-population-regression-function-prf" class="nav-link" data-scroll-target="#the-population-regression-function-prf"><span class="header-section-number">1.3.1</span> The Population Regression Function (PRF)</a></li>
  <li><a href="#the-sample-regression-function-srf" id="toc-the-sample-regression-function-srf" class="nav-link" data-scroll-target="#the-sample-regression-function-srf"><span class="header-section-number">1.3.2</span> The Sample Regression Function (SRF)</a></li>
  </ul></li>
  <li><a href="#the-ordinary-least-squares-ols-method" id="toc-the-ordinary-least-squares-ols-method" class="nav-link" data-scroll-target="#the-ordinary-least-squares-ols-method"><span class="header-section-number">1.4</span> The Ordinary Least Squares (OLS) Method</a>
  <ul class="collapse">
  <li><a href="#intuition-behind-the-ols-estimators" id="toc-intuition-behind-the-ols-estimators" class="nav-link" data-scroll-target="#intuition-behind-the-ols-estimators"><span class="header-section-number">1.4.1</span> Intuition behind the OLS estimators</a></li>
  <li><a href="#fitting-an-ols-model-in-r" id="toc-fitting-an-ols-model-in-r" class="nav-link" data-scroll-target="#fitting-an-ols-model-in-r"><span class="header-section-number">1.4.2</span> Fitting an OLS Model in R</a></li>
  </ul></li>
  <li><a href="#derivation-of-the-ols-estimators" id="toc-derivation-of-the-ols-estimators" class="nav-link" data-scroll-target="#derivation-of-the-ols-estimators"><span class="header-section-number">1.5</span> Derivation of the OLS Estimators</a>
  <ul class="collapse">
  <li><a href="#the-minimization-problem" id="toc-the-minimization-problem" class="nav-link" data-scroll-target="#the-minimization-problem"><span class="header-section-number">1.5.1</span> The Minimization Problem</a></li>
  <li><a href="#the-normal-equations" id="toc-the-normal-equations" class="nav-link" data-scroll-target="#the-normal-equations"><span class="header-section-number">1.5.2</span> The Normal Equations</a></li>
  <li><a href="#solving-the-normal-equations" id="toc-solving-the-normal-equations" class="nav-link" data-scroll-target="#solving-the-normal-equations"><span class="header-section-number">1.5.3</span> Solving the Normal Equations</a></li>
  </ul></li>
  <li><a href="#standard-errors-of-the-ols-estimators" id="toc-standard-errors-of-the-ols-estimators" class="nav-link" data-scroll-target="#standard-errors-of-the-ols-estimators"><span class="header-section-number">1.6</span> Standard Errors of the OLS Estimators</a>
  <ul class="collapse">
  <li><a href="#the-formula-for-the-standard-error-of-hatbeta" id="toc-the-formula-for-the-standard-error-of-hatbeta" class="nav-link" data-scroll-target="#the-formula-for-the-standard-error-of-hatbeta"><span class="header-section-number">1.6.1</span> The Formula for the Standard Error of <span class="math inline">\(\hat{\beta}\)</span></a></li>
  <li><a href="#what-drives-the-standard-error" id="toc-what-drives-the-standard-error" class="nav-link" data-scroll-target="#what-drives-the-standard-error"><span class="header-section-number">1.6.2</span> What Drives the Standard Error?</a></li>
  <li><a href="#calculating-standard-errors" id="toc-calculating-standard-errors" class="nav-link" data-scroll-target="#calculating-standard-errors"><span class="header-section-number">1.6.3</span> Calculating Standard Errors</a></li>
  </ul></li>
  <li><a href="#hypothesis-testing-and-standard-errors" id="toc-hypothesis-testing-and-standard-errors" class="nav-link" data-scroll-target="#hypothesis-testing-and-standard-errors"><span class="header-section-number">1.7</span> Hypothesis Testing and Standard Errors</a></li>
  <li><a href="#measures-of-fit-how-well-does-the-line-explain-the-data" id="toc-measures-of-fit-how-well-does-the-line-explain-the-data" class="nav-link" data-scroll-target="#measures-of-fit-how-well-does-the-line-explain-the-data"><span class="header-section-number">1.8</span> Measures of Fit: How Well Does the Line Explain the Data?</a>
  <ul class="collapse">
  <li><a href="#the-r-squared-r2" id="toc-the-r-squared-r2" class="nav-link" data-scroll-target="#the-r-squared-r2"><span class="header-section-number">1.8.1</span> The R-Squared (<span class="math inline">\(R^2\)</span>)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Simple Regression Model: Basics of OLS</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1.1</span> Introduction</h2>
<p>Economic theory suggests relationships between variables, but it rarely provides the <em>quantitative magnitude</em> of these causal effects. For example, we are interested in questions such as:</p>
<ul>
<li>What is the effect of <strong>reducing class size</strong> on student academic performance?</li>
<li>What is the <strong>price elasticity</strong> of cigarettes?</li>
<li>What is the <strong>return to an additional year</strong> of education?</li>
<li>How does a <strong>1 percentage point increase in interest rates</strong> affect output growth?</li>
</ul>
<p>Ideally, we would answer these questions with <strong>controlled experiments</strong>. However, this is often impractical, unethical, or impossible. Instead, econometricians must rely on <strong>observational data</strong>.</p>
<p>The core challenge with observational studies is that <strong>correlation does not imply causation</strong>. Some major threats to establishing a proper empirical understanding of economic relationships are:</p>
<ol type="1">
<li><strong>Omitted Variable Bias (Confounding Factors):</strong> A variable we have not accounted for is influencing <strong>both</strong> the dependent and independent variable.</li>
<li><strong>Simultaneous Causality:</strong> Two variables influence each other simultaneously (e.g., police numbers and crime rates).</li>
<li><strong>Sample Selection Bias:</strong> The process by which data is collected influences the availability of data, leading to a non-random sample that may not represent the population of interest.</li>
</ol>
<p>As a way of introduction, we introduce the primary tools used to estimate relationships from observational data in econometrics: the <strong>Ordinary Least Squares (OLS)</strong> method.</p>
</section>
<section id="types-of-data" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="types-of-data"><span class="header-section-number">1.2</span> Types of Data</h2>
<p>Before we begin, it’s useful to recognize the common structures of econometric data:</p>
<ul>
<li><strong>Cross-sectional:</strong> Data on multiple entities (individuals, firms, countries) at a single point in time.</li>
<li><strong>Time-series:</strong> Data on a single entity collected at multiple time periods (e.g., daily, quarterly, yearly).</li>
<li><strong>Panel/Longitudinal:</strong> Data on multiple entities where each entity is observed at multiple time periods. This combines cross-sectional and time-series dimensions.</li>
<li><strong>Pooled Cross-sectional:</strong> Multiple cross-sectional samples taken at different points in time, where the entities in each sample are different.</li>
</ul>
</section>
<section id="the-simple-regression-model" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="the-simple-regression-model"><span class="header-section-number">1.3</span> The Simple Regression Model</h2>
<p>Let’s begin by investigating the linear relationship between two variables, <span class="math inline">\(Y\)</span> (the dependent variable) and <span class="math inline">\(X\)</span> (the independent or explanatory variable).</p>
<section id="the-population-regression-function-prf" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="the-population-regression-function-prf"><span class="header-section-number">1.3.1</span> The Population Regression Function (PRF)</h3>
<p>Imagine we could collect data on <em>everyone</em> in the population of interest. The true relationship in the population is given by the <strong>Population Regression Function</strong>:</p>
<p><span class="math display">\[Y_i = \alpha + \beta X_i + u_i\]</span></p>
<ul>
<li><span class="math inline">\(Y_i\)</span> is the dependent variable for observation <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(X_i\)</span> is the independent variable for observation <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(\alpha\)</span> is the <strong>population intercept</strong>.</li>
<li><span class="math inline">\(\beta\)</span> is the <strong>population slope</strong> coefficient (the parameter of primary interest).</li>
<li><span class="math inline">\(u_i\)</span> is the <strong>error term</strong>, which contains all factors other than <span class="math inline">\(X\)</span> that influence <span class="math inline">\(Y\)</span>.</li>
</ul>
<p>We can never observe the true PRF because we cannot collect data on the entire population. The error term <span class="math inline">\(u_i\)</span> exists due to: (1) The inherent randomness of human behavior, (2) Unavailable or incomplete data, (3) Omitted variables from the model, (4) Imperfect functional form specification, (5) Aggregation errors, (6) Measurement errors.</p>
</section>
<section id="the-sample-regression-function-srf" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="the-sample-regression-function-srf"><span class="header-section-number">1.3.2</span> The Sample Regression Function (SRF)</h3>
<p>Since we can’t work with the population, we take a sample and use it to <em>estimate</em> the PRF. The estimated model is called the <strong>Sample Regression Function</strong>:</p>
<p><span class="math display">\[\hat{Y}_i = \hat{\alpha} + \hat{\beta} X_i\]</span></p>
<p><span class="math display">\[Y_i = \hat{\alpha} + \hat{\beta} X_i + \hat{u}_i\]</span></p>
<ul>
<li><span class="math inline">\(\hat{Y}_i\)</span> is the <strong>predicted</strong> or <strong>fitted value</strong> of <span class="math inline">\(Y_i\)</span>.</li>
<li><span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> are the <strong>estimators</strong> of the population parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. These coefficients are calculated from our sample data.</li>
<li><span class="math inline">\(\hat{u}_i = Y_i - \hat{Y}_i\)</span> is the <strong>residual</strong> for observation <span class="math inline">\(i\)</span>, which is our estimate of the unobserved error term <span class="math inline">\(u_i\)</span>.</li>
</ul>
</section>
</section>
<section id="the-ordinary-least-squares-ols-method" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="the-ordinary-least-squares-ols-method"><span class="header-section-number">1.4</span> The Ordinary Least Squares (OLS) Method</h2>
<p>How do we find the “best” line through our scatter of data points? The OLS method chooses <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> that minimizes the <strong>Sum of Squared Residuals (SSR)</strong>.</p>
<p><span class="math display">\[\min_{\hat{\alpha}, \hat{\beta}} \sum_{i=1}^n \hat{u}_i^2 = \min_{\hat{\alpha}, \hat{\beta}} \sum_{i=1}^n (Y_i - \hat{\alpha} - \hat{\beta} X_i)^2\]</span></p>
<p>The formulas for the OLS estimators, derived by solving this minimization problem (the “normal equations”), are:</p>
<p><span class="math display">\[\hat{\beta} = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2} = \frac{\sum_{i=1}^n x_i y_i}{\sum_{i=1}^n x_i^2}\]</span></p>
<p><span class="math display">\[\hat{\alpha} = \bar{Y} - \hat{\beta}\bar{X}\]</span></p>
<section id="intuition-behind-the-ols-estimators" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="intuition-behind-the-ols-estimators"><span class="header-section-number">1.4.1</span> Intuition behind the OLS estimators</h3>
<p>The formulas for <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> aren’t arbitrary; they are the direct mathematical solution to the problem of minimizing the sum of squared residuals. But we can also understand them intuitively.</p>
<section id="intuition-for-the-slope-hatbeta" class="level4" data-number="1.4.1.1">
<h4 data-number="1.4.1.1" class="anchored" data-anchor-id="intuition-for-the-slope-hatbeta"><span class="header-section-number">1.4.1.1</span> Intuition for the Slope (<span class="math inline">\(\hat{\beta}\)</span>)</h4>
<p>Let’s look at the formula for the slope estimator more closely:</p>
<p><span class="math display">\[\hat{\beta} = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}\]</span></p>
<ul>
<li>Dividing the numerator by <span class="math inline">\(n\)</span> gives <span class="math inline">\(\frac{1}{n-1} \sum (X_i - \bar{X})(Y_i - \bar{Y})\)</span>, which is the <strong>sample covariance</strong> between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Recall that the covariance measures how two variables move together:
<ul>
<li>If <span class="math inline">\(X\)</span> is above its mean when <span class="math inline">\(Y\)</span> is above its mean (and vice versa), the products <span class="math inline">\((X_i - \bar{X})(Y_i - \bar{Y})\)</span> will be positive, leading to a positive covariance and a positive <span class="math inline">\(\hat{\beta}\)</span>.</li>
<li>If <span class="math inline">\(X\)</span> is above its mean when <span class="math inline">\(Y\)</span> is below its mean, the products will be negative, leading to a negative covariance and a negative <span class="math inline">\(\hat{\beta}\)</span>.</li>
</ul></li>
<li>Note also that dividing the denominator by <span class="math inline">\(n\)</span> gives <span class="math inline">\(\frac{1}{n-1} \sum (X_i - \bar{X})^2\)</span>, which is the <strong>sample variance</strong> of <span class="math inline">\(X\)</span>. The variance measures the spread or variation of <span class="math inline">\(X\)</span> around its own mean.</li>
</ul>
<p>So, we can think of <span class="math inline">\(\hat{\beta}\)</span> as: <span class="math display">\[\hat{\beta} = \frac{\text{Sample Covariance between X and Y}}{\text{Sample Variance of X}}\]</span></p>
<p>In other words, the OLS slope estimator answers the question: “For a given amount of movement in <span class="math inline">\(X\)</span>, how much associated movement do we see in <span class="math inline">\(Y\)</span>?” It <strong>scales</strong> the co-movement of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> by the movement in <span class="math inline">\(X\)</span> itself. A steeper slope (larger <span class="math inline">\(|\hat{\beta}|\)</span>) means a unit change in <span class="math inline">\(X\)</span> is associated with a larger change in <span class="math inline">\(Y\)</span>.</p>
</section>
<section id="intuition-for-the-intercept-hatalpha" class="level4" data-number="1.4.1.2">
<h4 data-number="1.4.1.2" class="anchored" data-anchor-id="intuition-for-the-intercept-hatalpha"><span class="header-section-number">1.4.1.2</span> Intuition for the Intercept (<span class="math inline">\(\hat{\alpha}\)</span>)</h4>
<p>The formula for the intercept is: <span class="math display">\[\hat{\alpha} = \bar{Y} - \hat{\beta}\bar{X}\]</span></p>
<p>This ensures that the regression line <strong>always passes through the point of the means</strong> <span class="math inline">\((\bar{X}, \bar{Y})\)</span>. Think of it as an “anchor” point for the line.</p>
<ul>
<li><span class="math inline">\(\hat{\beta}\bar{X}\)</span> tells us where the regression line would predict <span class="math inline">\(\bar{Y}\)</span> to be based <em>only</em> on the average value of <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\(\bar{Y} - \hat{\beta}\bar{X}\)</span> is the adjustment needed so that the prediction is correct precisely at the means. It represents the predicted value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X = 0\)</span>, which may or may not be a meaningful value depending on the context (e.g., predicting a company’s profit when revenue is zero might not be sensible).</li>
</ul>
</section>
<section id="the-core-idea-of-least-squares" class="level4" data-number="1.4.1.3">
<h4 data-number="1.4.1.3" class="anchored" data-anchor-id="the-core-idea-of-least-squares"><span class="header-section-number">1.4.1.3</span> The Core Idea of “Least Squares”</h4>
<p>The goal is to minimize the sum of <strong>squared</strong> residuals (<span class="math inline">\(\sum \hat{u}_i^2\)</span>). Why squares? 1. <strong>Squaring penalizes large errors more severely than small errors.</strong> A residual of 2 is four times “worse” than a residual of 1 <span class="math inline">\((2^2 = 4\)</span> vs.&nbsp;<span class="math inline">\(1^2 = 1)\)</span>. This makes the estimator very sensitive to outliers. 2. <strong>Squaring ensures all errors are positive.</strong> We don’t want positive and negative errors to cancel each other out. 3. <strong>The math works out nicely.</strong> Minimizing a quadratic function (like the sum of squares) leads to the clean, linear equations (“normal equations”) that give us the formulas for <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span>.</p>
<p>The OLS method therefore finds the unique line that minimizes the <em>total squared vertical distance</em> between the observed data points <span class="math inline">\((X_i, Y_i)\)</span> and the line itself. It’s a best-fit line by its own specific definition of “best” (minimum sum of squared errors).</p>
</section>
</section>
<section id="fitting-an-ols-model-in-r" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="fitting-an-ols-model-in-r"><span class="header-section-number">1.4.2</span> Fitting an OLS Model in R</h3>
<p>Let’s use the <code>mtcars</code> dataset to estimate a simple regression model, predicting miles per gallon (<code>mpg</code>) using car weight (<code>wt</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the built-in dataset</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate the OLS model</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print a summary of the results</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
</div>
</div>
<p>The output shows our estimated coefficients is <span class="math inline">\(\hat{\alpha}\)</span> (Intercept) = 37.29 and <span class="math inline">\(\hat{\beta}\)</span> (wt) = -5.34</p>
<p>This gives us the Sample Regression Line</p>
<p><span class="math display">\[\widehat{mpg}_i = 37.29 - 5.34 \times wt_i\]</span></p>
<p>Hence, for a one-ton increase in car weight, we predict miles per gallon will decrease by about 5.34 units.</p>
</section>
</section>
<section id="derivation-of-the-ols-estimators" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="derivation-of-the-ols-estimators"><span class="header-section-number">1.5</span> Derivation of the OLS Estimators</h2>
<p>The formulas for <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> are derived by solving the minimization problem of the Sum of Squared Residuals (SSR). This process involves calculus, specifically taking derivatives and setting them to zero to find the minimum. The resulting equations are called the <strong>normal equations</strong>.</p>
<section id="the-minimization-problem" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="the-minimization-problem"><span class="header-section-number">1.5.1</span> The Minimization Problem</h3>
<p>We aim to find the values of <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> that minimize: <span class="math display">\[S(\hat{\alpha}, \hat{\beta}) = \sum_{i=1}^n \hat{u}_i^2 = \sum_{i=1}^n (Y_i - \hat{\alpha} - \hat{\beta} X_i)^2\]</span></p>
</section>
<section id="the-normal-equations" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="the-normal-equations"><span class="header-section-number">1.5.2</span> The Normal Equations</h3>
<p>To find the minimum, we take the partial derivatives of <span class="math inline">\(S(\hat{\alpha}, \hat{\beta})\)</span> with respect to <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> and set them equal to zero.</p>
<ol type="1">
<li><p><strong>Derivative with respect to</strong> <span class="math inline">\(\hat{\alpha}\)</span>: <span class="math display">\[\frac{\partial S}{\partial \hat{\alpha}} = -2 \sum_{i=1}^n (Y_i - \hat{\alpha} - \hat{\beta} X_i) = 0\]</span> This simplifies to the <strong>first normal equation</strong>: <span class="math display">\[\sum_{i=1}^n Y_i = n\hat{\alpha} + \hat{\beta} \sum_{i=1}^n X_i \quad \text{(1)}\]</span></p></li>
<li><p><strong>Derivative with respect to</strong> <span class="math inline">\(\hat{\beta}\)</span>: <span class="math display">\[\frac{\partial S}{\partial \hat{\beta}} = -2 \sum_{i=1}^n X_i(Y_i - \hat{\alpha} - \hat{\beta} X_i) = 0\]</span> This simplifies to the <strong>second normal equation</strong>: <span class="math display">\[\sum_{i=1}^n X_iY_i = \hat{\alpha} \sum_{i=1}^n X_i + \hat{\beta} \sum_{i=1}^n X_i^2 \quad \text{(2)}\]</span></p></li>
</ol>
</section>
<section id="solving-the-normal-equations" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="solving-the-normal-equations"><span class="header-section-number">1.5.3</span> Solving the Normal Equations</h3>
<p>We now have a system of two equations with two unknowns (<span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span>).</p>
<ol type="1">
<li><p><strong>Solving for</strong> <span class="math inline">\(\hat{\alpha}\)</span>: Start by rearranging the first normal equation (1): <span class="math display">\[\hat{\alpha} = \bar{Y} - \hat{\beta}\bar{X}\]</span> where <span class="math inline">\(\bar{Y} = \frac{1}{n}\sum Y_i\)</span> and <span class="math inline">\(\bar{X} = \frac{1}{n}\sum X_i\)</span>. This is our formula for the intercept.</p></li>
<li><p><strong>Solving for</strong> <span class="math inline">\(\hat{\beta}\)</span>: Substitute the expression for <span class="math inline">\(\hat{\alpha}\)</span> into the second normal equation (2): <span class="math display">\[\sum X_iY_i = (\bar{Y} - \hat{\beta}\bar{X})\sum X_i + \hat{\beta} \sum X_i^2\]</span> Solving this for <span class="math inline">\(\hat{\beta}\)</span> involves some algebra. Subtract <span class="math inline">\(\bar{Y}\sum X_i\)</span> from both sides and factor out <span class="math inline">\(\hat{\beta}\)</span>: <span class="math display">\[\sum X_iY_i - \bar{Y}\sum X_i = \hat{\beta} \left( \sum X_i^2 - \bar{X}\sum X_i \right)\]</span> Note that <span class="math inline">\(\sum X_iY_i - \bar{Y}\sum X_i = \sum (X_i - \bar{X})(Y_i - \bar{Y})\)</span> and <span class="math inline">\(\sum X_i^2 - \bar{X}\sum X_i = \sum (X_i - \bar{X})^2\)</span>. This gives us the final formula: <span class="math display">\[\hat{\beta} = \frac{\sum (X_i - \bar{X})(Y_i - \bar{Y})}{\sum (X_i - \bar{X})^2} = \frac{\sum_{i=1}^n x_i y_i}{\sum_{i=1}^n x_i^2}\]</span></p></li>
</ol>
</section>
</section>
<section id="standard-errors-of-the-ols-estimators" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="standard-errors-of-the-ols-estimators"><span class="header-section-number">1.6</span> Standard Errors of the OLS Estimators</h2>
<p>The OLS estimators <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> are random variables—their values vary from sample to sample. The <strong>standard error</strong> measures the precision of these estimates by estimating the standard deviation of their sampling distributions. Smaller standard errors indicate more precise estimates.</p>
<section id="the-formula-for-the-standard-error-of-hatbeta" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="the-formula-for-the-standard-error-of-hatbeta"><span class="header-section-number">1.6.1</span> The Formula for the Standard Error of <span class="math inline">\(\hat{\beta}\)</span></h3>
<p>To conduct statistical inference on our OLS estimate <span class="math inline">\(\hat{\beta}\)</span> (e.g., to build confidence intervals or test hypotheses), we need to estimate its sampling variability. This variability is measured by its <strong>variance</strong> or, more commonly, its <strong>standard error</strong>.</p>
<p><strong>The True Variance of <span class="math inline">\(\hat{\beta}\)</span></strong></p>
<p>Under the classical linear model assumptions, the true variance of the OLS slope estimator in a simple regression is given by:</p>
<p><span class="math display">\[Var(\hat{\beta}) = \frac{\sigma^2}{\sum_{i=1}^n (X_i - \bar{X})^2}\]</span></p>
<p>where, <span class="math inline">\(\sigma^2 = Var(u_i)\)</span> is the <strong>variance of the unobserved error term</strong>, and <span class="math inline">\(\sum_{i=1}^n (X_i - \bar{X})^2\)</span> is the total variation of the independent variable <span class="math inline">\(X\)</span> around its mean.</p>
<p>This formula shows that the precision of <span class="math inline">\(\hat{\beta}\)</span> improves (its variance decreases) when either (1) the error variance (<span class="math inline">\(\sigma^2\)</span>) is smaller (the data points are tighter around the line, and/or (2) the spread of the explanatory variable <span class="math inline">\(X\)</span> is larger (there is more information in the data).</p>
<p><strong>Estimating the Unknown Error Variance (<span class="math inline">\(\sigma^2\)</span>)</strong></p>
<p>Since the error variance <span class="math inline">\(\sigma^2\)</span> is unknown, we must estimate it using the sample data. An unbiased estimator for <span class="math inline">\(\sigma^2\)</span> is</p>
<p><span class="math display">\[\hat{\sigma}^2 = \frac{1}{n - k} \sum_{i=1}^n \hat{u}_i^2   \quad \text{or}   \quad \frac{SSR}{n - k}\]</span></p>
<p>where, <span class="math inline">\(SSR = \sum_{i=1}^n \hat{u}_i^2\)</span> is the <strong>Sum of Squared Residuals (SSR)</strong>, <span class="math inline">\(n\)</span> is the sample size, and <span class="math inline">\(k\)</span> is the total number of parameters estimated. In a simple regression, we estimate two parameters, i.e.&nbsp;the slope (<span class="math inline">\(\beta\)</span>) and the intercept (<span class="math inline">\(\alpha\)</span>), so <span class="math inline">\(k=2\)</span>. The term <span class="math inline">\(n - k\)</span> is the <strong>degrees of freedom</strong>. Using <span class="math inline">\(n-k\)</span> instead of <span class="math inline">\(n\)</span> ensures that <span class="math inline">\(E[\hat{\sigma}^2] = \sigma^2\)</span>, making it an unbiased estimator.</p>
<p><strong>The Standard Error of the Regression (SER)</strong></p>
<p>The square root of <span class="math inline">\(\hat{\sigma}^2\)</span> is called the <strong>Standard Error of the Regression (SER)</strong> or the residual standard error. It is an estimate of the standard deviation of the error term <span class="math inline">\(u_i\)</span> and represents the average distance that the observed values fall from the regression line—the typical size of a residual.</p>
<p><span class="math display">\[SER = \sqrt{\hat{\sigma}^2} = \sqrt{\frac{SSR}{n - k}}\]</span></p>
<p><strong>The Estimated Variance and Standard Error of <span class="math inline">\(\hat{\beta}\)</span></strong></p>
<p>By plugging the estimate <span class="math inline">\(\hat{\sigma}^2\)</span> into the true variance formula, we obtain the <strong>estimated variance</strong> of the OLS estimator</p>
<p><span class="math display">\[\widehat{Var}(\hat{\beta}) = \frac{\hat{\sigma}^2}{\sum_{i=1}^n (X_i - \bar{X})^2}\]</span></p>
<p>The <strong>standard error of <span class="math inline">\(\hat{\beta}\)</span></strong> is simply the square root of this estimated variance. It is the estimated standard deviation of the sampling distribution of <span class="math inline">\(\hat{\beta}\)</span>.</p>
<p><span class="math display">\[SE(\hat{\beta}) = \sqrt{\widehat{Var}(\hat{\beta})} = \frac{\hat{\sigma}}{\sqrt{\sum_{i=1}^n (X_i - \bar{X})^2}} \quad \text{or} \quad \hat{\sigma} \sqrt{\frac{1}{\sum_{i=1}^n x^2}}\]</span></p>
<p>This final formula is the most intuitive: the standard error of the coefficient depends directly on the “noise” in the model (<span class="math inline">\(SER\)</span>) and inversely on the amount of information in the explanatory variable, i.e.&nbsp;<span class="math inline">\(\sqrt{\sum_{i=1}^n x^2}\)</span>.</p>
</section>
<section id="what-drives-the-standard-error" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="what-drives-the-standard-error"><span class="header-section-number">1.6.2</span> What Drives the Standard Error?</h3>
<p>The formula for <span class="math inline">\(SE(\hat{\beta})\)</span> provides deep intuition about what makes an estimate precise: 1. <strong>Spread of the error term (</strong><span class="math inline">\(\hat{\sigma}\)</span>): A larger error variance (a noisier relationship, where points are scattered farther from the line) leads to a <strong>larger standard error</strong> and less precise estimates. 2. <strong>Sample size (</strong><span class="math inline">\(n\)</span>): A larger sample size <span class="math inline">\(n\)</span> will (all else equal) make <span class="math inline">\(\hat{\sigma}\)</span> smaller and the denominator larger, leading to a <strong>smaller standard error</strong> and more precise estimates. 3. <strong>Spread of the regressor</strong> <span class="math inline">\(X\)</span> (<span class="math inline">\(SST_X\)</span>): More variation in the independent variable <span class="math inline">\(X\)</span> provides more “information” and leads to a <strong>smaller standard error</strong>. If all values of <span class="math inline">\(X\)</span> are clustered closely together, it is harder to pin down the slope of the relationship.</p>
<p>The standard error for the intercept <span class="math inline">\(\hat{\alpha}\)</span> has a more complex formula but is driven by the same factors: <span class="math inline">\(n\)</span>, <span class="math inline">\(\hat{\sigma}\)</span>, and the spread of <span class="math inline">\(X\)</span>.</p>
</section>
<section id="calculating-standard-errors" class="level3" data-number="1.6.3">
<h3 data-number="1.6.3" class="anchored" data-anchor-id="calculating-standard-errors"><span class="header-section-number">1.6.3</span> Calculating Standard Errors</h3>
<p>Usually, you don’t need to calculate these by hand. In R, the <code>summary()</code> function computes them automatically using the formulas above.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-running the model from earlier for clarity</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The summary output shows the coefficients and their standard errors</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>summary_model <span class="ot">&lt;-</span> <span class="fu">summary</span>(model)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(summary_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
</div>
</div>
<p>In the output, the <code>Std. Error</code> column next to the <code>(Intercept)</code> and <code>wt</code> estimates contains the calculated <span class="math inline">\(SE(\hat{\alpha})\)</span> and <span class="math inline">\(SE(\hat{\beta})\)</span>. These values are used to compute the t-statistics and p-values for hypothesis testing, allowing us to assess the statistical significance of our estimates.</p>
</section>
</section>
<section id="hypothesis-testing-and-standard-errors" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="hypothesis-testing-and-standard-errors"><span class="header-section-number">1.7</span> Hypothesis Testing and Standard Errors</h2>
<p>Our estimates <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> are random—they would change if we collected a new sample. To conduct statistical inference, we need to estimate their variability, which is captured by the <strong>Standard Error (S.E.)</strong>.</p>
<p>The most common hypothesis test in regression is whether the slope coefficient <span class="math inline">\(\beta\)</span> is statistically different from zero.</p>
<p><span class="math inline">\(H_0: \beta = 0\)</span> (There is <em>no</em> relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>) vs.&nbsp;<span class="math inline">\(H_1: \beta \neq 0\)</span> (There <em>is</em> a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>)</p>
<p>We use a <strong>t-test</strong> to evaluate this hypothesis, where the test statistic is</p>
<p><span class="math display">\[TS = \frac{\hat{\beta} - 0}{SE(\hat{\beta})}\]</span></p>
<p>You can reject the null hypothesis (<span class="math inline">\(H_0\)</span>) if</p>
<ol type="1">
<li><p><strong>|t-statistic| &gt; critical value</strong> (approx. “2” for a 5% significance level)</p></li>
<li><p><strong>p-value &lt; significance level</strong> (e.g., <span class="math inline">\(\alpha = 0.05\)</span>). The p-value is the probability of observing a result as extreme as the one in your sample if the null hypothesis were true.</p></li>
<li><p>If the <strong>95% confidence interval</strong> <span class="math inline">\([\hat{\beta} - 1.96 \cdot SE(\hat{\beta}), \hat{\beta} + 1.96 \cdot SE(\hat{\beta})]\)</span> does not contain zero.</p></li>
</ol>
<p>In our <code>mtcars</code> output</p>
<ul>
<li><p>The t-statistic for <code>wt</code> is -9.559.</p></li>
<li><p>The p-value is <code>1.29e-10</code> (effectively 0), which is much less than 0.05.</p></li>
<li><p>The 95% confidence interval can be calculated with <code>confint(model)</code> and will not contain zero.</p></li>
</ul>
<p><strong>Conclusion:</strong> We strongly reject the null hypothesis. Hence there is a statistically significant relationship between car weight and fuel efficiency at the 5% level.</p>
</section>
<section id="measures-of-fit-how-well-does-the-line-explain-the-data" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="measures-of-fit-how-well-does-the-line-explain-the-data"><span class="header-section-number">1.8</span> Measures of Fit: How Well Does the Line Explain the Data?</h2>
<p>Once we have our regression line, we want to know how well it fits the data. We decompose the total variation in <span class="math inline">\(Y\)</span>:</p>
<ul>
<li><strong>SST (Total Sum of Squares):</strong> Total variation in <span class="math inline">\(Y\)</span> around its mean. <span class="math inline">\(SST = \sum (Y_i - \bar{Y})^2\)</span></li>
<li><strong>SSE (Explained Sum of Squares):</strong> Variation in <span class="math inline">\(Y\)</span> explained by the model. <span class="math inline">\(SSE = \sum (\hat{Y}_i - \bar{Y})^2\)</span></li>
<li><strong>SSR (Residual Sum of Squares):</strong> Variation in <span class="math inline">\(Y\)</span> <em>not</em> explained by the model. <span class="math inline">\(SSR = \sum \hat{u}_i^2\)</span></li>
</ul>
<p>They are related by the identity: <span class="math inline">\(SST = SSE + SSR\)</span>.</p>
<section id="the-r-squared-r2" class="level3" data-number="1.8.1">
<h3 data-number="1.8.1" class="anchored" data-anchor-id="the-r-squared-r2"><span class="header-section-number">1.8.1</span> The R-Squared (<span class="math inline">\(R^2\)</span>)</h3>
<p>The most common measure of fit is the <strong>R-squared</strong> statistic. It represents the <strong>fraction of the sample variation in</strong> <span class="math inline">\(Y\)</span> that is explained by <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[R^2 = \frac{SSE}{SST} = 1 - \frac{SSR}{SST}\]</span></p>
<ul>
<li><span class="math inline">\(R^2\)</span> always lies between 0 and 1.</li>
<li>An <span class="math inline">\(R^2\)</span> of 0 means <span class="math inline">\(X\)</span> explains none of the variation in <span class="math inline">\(Y\)</span>.</li>
<li>An <span class="math inline">\(R^2\)</span> of 1 means <span class="math inline">\(X\)</span> explains all of the variation in <span class="math inline">\(Y\)</span>.</li>
<li>In a <strong>simple</strong> regression, <span class="math inline">\(R^2\)</span> is also the square of the correlation coefficient between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, that is,<span class="math inline">\(R^2 = r_{xy}^2\)</span>.</li>
</ul>
<p>In our <code>mtcars</code> example, the <span class="math inline">\(R^2\)</span> is 0.7528. This means that about 75% of the variation in miles per gallon is explained by the weight of the car.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Welcome">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Welcome</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./assumptions.html" class="pagination-link" aria-label="The Classical Linear Model (Gauss-Markov) Assumptions">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Classical Linear Model (Gauss-Markov) Assumptions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>